{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VECTR Link Analysis with Gephi and ipysigma\n",
    "\n",
    "[Gephi](https://gephi.org) and other link analysis tools can be used to surface trends within a VECTR dataset, allowing defenders to focus their efforts on prevalent techniques observed across a range of threat groups. This Jupyter Notebook processes a standard VECTR Environment CSV export, returning an in-line node graph, as well as `node.csv` and `edge.csv` inputs for use within Gephi. The subsequent analysis be used to discover commonalities between Threat Actors (VECTR Assessments), their intrusions (VECTR Campaigns), and corresponding MITRE ATT&CK Tactics, Tools and Techniques (VECTR Test Cases).\n",
    "\n",
    "Note, that this methodology works best when your VECTR Environment is organised to reflect the approach documented in my original presentation, *[Intelligence-Led Adversarial Threat Modelling with VECTR](https://github.com/ssnkhan/adversarial-threat-modelling)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "# Wednesday 15 January 2025\n",
    "# Sajid Nawaz Khan, HSBC CITA\n",
    "# @snkhan@infosec.exchange\n",
    "\n",
    "# Intelligence-Led Adversarial Threat Modelling with VECTR\n",
    "# See https://github.com/ssnkhan/adversarial-threat-modelling\n",
    "# Takes a VECTR Environment export (CSV), and generates a directed graph using ipysigma\n",
    "# Additionally, generates inputs for use within Gephi\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Hide Future Warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the VECTR CSV\n",
    "# Generate via {Environment} ▶ Export Active Environment\n",
    "\n",
    "vectr_df = pd.read_csv(\"./VECTR.csv\")\n",
    "vectr_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "# Filter Campaigns by Threat Group or Year, or both\n",
    "# Expects Campaign names to be prefixed with YYYY\n",
    "\n",
    "# List of values -- empty returns all\n",
    "threat_actor_include = [\"\"]\n",
    "threat_actor_exclude = [\"Red Team\"]\n",
    "year = [\"\"]\n",
    "\n",
    "\n",
    "# Filter by one specific list\n",
    "vectr_filtered_df = vectr_df[vectr_df[\"AssessmentGroup\"].str.contains(\"|\".join(threat_actor_include), na=False)]\n",
    "vectr_filtered_df = vectr_df[~vectr_df[\"AssessmentGroup\"].str.contains(\"|\".join(threat_actor_exclude), na=False)]\n",
    "vectr_filtered_df = vectr_df[vectr_df[\"Campaign\"].str.startswith(tuple(year))]\n",
    "\n",
    "\n",
    "# Or all\n",
    "# If `threat_actor_exclude` is an empty list, remove line 20 below\n",
    "vectr_filtered_df = vectr_df[\n",
    "    (vectr_df[\"AssessmentGroup\"].str.contains(\"|\".join(threat_actor_include), na=False)) &\n",
    "    ~vectr_df[\"AssessmentGroup\"].str.contains(\"|\".join(threat_actor_exclude), na=False) &\n",
    "    (vectr_df[\"Campaign\"].str.startswith(tuple(year)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below to use the filtered dataframe\n",
    "# vectr_df = vectr_filtered_df\n",
    "\n",
    "actor_tactic_technique_df = vectr_df[[\"AssessmentGroup\", \"Phase\", \"MitreID\", \"Method\", \"Attacker Tools\"]].copy()\n",
    "actor_tactic_technique_df.rename(columns={\"AssessmentGroup\":\"Actor\", \"Phase\":\"Tactic\", \"MitreID\":\"Technique\", \"Attacker Tools\":\"Tool\"}, inplace=True)\n",
    "actor_tactic_technique_df.value_counts()[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes\n",
    "# Columns: Id, Type, Label\n",
    "# Nodes tell Gephi all the possible nodes in a network\n",
    "\n",
    "gephi_nodes_df = pd.DataFrame(columns=[\"Id\", \"Type\", \"Label\"])\n",
    "gephi_nodes_df[\"Id\"] = actor_tactic_technique_df[\"Actor\"].values\n",
    "gephi_nodes_df[\"Type\"] = \"Threat Actor\"\n",
    "\n",
    "# last_row_df = gephi_nodes_df.index[-1] + 1\n",
    "# gephi_nodes_df = pd.concat([gephi_nodes_df, pd.DataFrame({\"Id\": actor_tactic_technique_df[\"Tactic\"]})], ignore_index=True)\n",
    "# gephi_nodes_df[\"Type\"][last_row_df:] = \"Tactic\"\n",
    "\n",
    "last_row_df = gephi_nodes_df.index[-1] + 1\n",
    "gephi_nodes_df = pd.concat([gephi_nodes_df, pd.DataFrame({\"Id\": actor_tactic_technique_df[\"Technique\"], \"Label\": actor_tactic_technique_df[\"Tactic\"] + \": \" + actor_tactic_technique_df[\"Method\"]})], ignore_index=True)\n",
    "gephi_nodes_df[\"Type\"][last_row_df:] = \"Technique\"\n",
    "\n",
    "\n",
    "# Account for Tool cells containing multiple comma seperated values\n",
    "last_row_df = gephi_nodes_df.index[-1] + 1\n",
    "gephi_nodes_df = pd.concat([gephi_nodes_df, pd.DataFrame({\"Id\": actor_tactic_technique_df[\"Tool\"]})], ignore_index=True)\n",
    "empty_rows_nodes = gephi_nodes_df[gephi_nodes_df[\"Type\"].isnull()]\n",
    "\n",
    "expanded_rows_nodes = (\n",
    "    empty_rows_nodes.assign(Id=empty_rows_nodes[\"Id\"].str.split(\",\"))\n",
    "    .explode(\"Id\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "non_empty_rows_nodes = gephi_nodes_df[gephi_nodes_df[\"Type\"].notnull()]\n",
    "gephi_nodes_df = pd.concat([non_empty_rows_nodes, expanded_rows_nodes], ignore_index=True)\n",
    "gephi_nodes_df[\"Type\"][last_row_df:] = \"Tool\"\n",
    "\n",
    "\n",
    "# Clean up empty rows, and duplicates\n",
    "gephi_nodes_df = gephi_nodes_df.sort_values(by=[\"Type\", \"Id\"])\n",
    "gephi_nodes_df = gephi_nodes_df.dropna(subset=[\"Id\"])\n",
    "gephi_nodes_df = gephi_nodes_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edges\n",
    "# Columns: Source, Target\n",
    "# Edges tell Gephi how the nodes are connected\n",
    "\n",
    "gephi_edges_df = pd.DataFrame(columns=[\"Source\", \"Target\", \"Type\"])\n",
    "\n",
    "\n",
    "# These columns can be reintroduced, but may create busy graphs\n",
    "# actor_tactic = pd.DataFrame({\"Source\": actor_tactic_technique_df[\"Actor\"], \"Target\": actor_tactic_technique_df[\"Tactic\"]})\n",
    "# gephi_edges_df = pd.concat([gephi_edges_df, actor_tactic], ignore_index=True)\n",
    "\n",
    "# tactic_technique = pd.DataFrame({\"Source\": actor_tactic_technique_df[\"Technique\"], \"Target\": actor_tactic_technique_df[\"Tactic\"]})\n",
    "# gephi_edges_df = pd.concat([gephi_edges_df, tactic_technique], ignore_index=True)\n",
    "\n",
    "\n",
    "actor_technique = pd.DataFrame({\"Source\": actor_tactic_technique_df[\"Actor\"], \"Target\": actor_tactic_technique_df[\"Technique\"]})\n",
    "gephi_edges_df = pd.concat([gephi_edges_df, actor_technique], ignore_index=True)\n",
    "\n",
    "\n",
    "# Account for Tool cells containing multiple, comma seperated values\n",
    "actor_tool = pd.DataFrame({\"Source\": actor_tactic_technique_df[\"Actor\"], \"Target\": actor_tactic_technique_df[\"Tool\"]})\n",
    "actor_tool_expanded = actor_tool.assign(Target=actor_tool[\"Target\"].str.split(\",\")).explode(\"Target\", ignore_index=True)\n",
    "actor_tool_expanded = actor_tool_expanded.dropna(subset=[\"Target\"])\n",
    "gephi_edges_df = pd.concat([gephi_edges_df, actor_tool_expanded], ignore_index=True)\n",
    "\n",
    "\n",
    "# Clean up empty rows, set Type to directed\n",
    "gephi_edges_df = gephi_edges_df.dropna(subset=[\"Source\", \"Target\"])\n",
    "gephi_edges_df[\"Type\"] = \"Directed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a graph using ipysigma\n",
    "# https://github.com/medialab/ipysigma\n",
    "# %pip install ipysigma networkx\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "from ipysigma import Sigma\n",
    "\n",
    "\n",
    "# Create a directed graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "\n",
    "# Populate the graph\n",
    "# Add nodes from our existing `gephi_nodes_df` dataframe\n",
    "for _, row in gephi_nodes_df.iterrows():\n",
    "    node_attributes = row.to_dict()\n",
    "    node_id = node_attributes.pop(\"Id\")\n",
    "    graph.add_node(node_id, **node_attributes)\n",
    "\n",
    "\n",
    "# Add edges from our existing `gephi_edges_df` dataframe\n",
    "for _, row in gephi_edges_df.iterrows():\n",
    "    edge_attributes = row.to_dict()\n",
    "    source = edge_attributes.pop(\"Source\")\n",
    "    target = edge_attributes.pop(\"Target\")\n",
    "    graph.add_edge(source, target, **edge_attributes)\n",
    "\n",
    "\n",
    "# Write the graph to a GEXF file\n",
    "nx.write_gexf(graph, \"./VECTR_Directed.gexf\")\n",
    "\n",
    "\n",
    "# Display the graph with the node size mapped on the node's in-degree, and the colour mapped to the node type\n",
    "# This emphasises the MITRE techniques, as well as the tools observed\n",
    "# Other `node_size` attributes to try: `graph.degree`, `graph.out_degree`,`nx.connected_components(graph)`, `nx.eigenvector_centrality(graph)`, `pagerank(graph)`\n",
    "\n",
    "# node_size\n",
    "# To emphasise tools and techniques, use `graph.in_degree`\n",
    "# To emphasise threat actors, use `graph.out_degree`\n",
    "\n",
    "Sigma(\n",
    "    graph,\n",
    "    name=\"VECTR Analysis\",\n",
    "    height=750, \n",
    "    node_metrics=[\"louvain\"],\n",
    "    default_edge_type=\"curve\", \n",
    "    node_size_range=(3, 20),\n",
    "    node_size=graph.in_degree, \n",
    "    default_node_color=\"#9370DB\", \n",
    "    node_color_palette=\"Purples\",\n",
    "    node_color=\"Type\",\n",
    "    node_halo_size=graph.in_degree,\n",
    "    node_halo_color=\"MediumBlue\",\n",
    "    start_layout=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save an offline, self-contained copy\n",
    "# Add `show_all_labels=True` to display all labels -- can make for a busy graph\n",
    "\n",
    "Sigma.write_html(\n",
    "    graph,\n",
    "    \"./VECTR_Directed.html\",\n",
    "    name=\"VECTR Analysis\",\n",
    "    fullscreen=True,\n",
    "    node_metrics=[\"louvain\"],\n",
    "    default_node_color=\"#20B2AA\", \n",
    "    node_color_palette=\"Purples\",\n",
    "    node_color=\"Type\",\n",
    "    node_size_range=(3, 20),\n",
    "    default_edge_type=\"curve\",\n",
    "    node_border_color_from=\"node\",\n",
    "    default_node_label_size=14,\n",
    "    node_size=graph.in_degree,\n",
    "    node_halo_size=graph.in_degree,\n",
    "    node_halo_color=\"MediumBlue\",\n",
    "    start_layout=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, use Gephi to generate, and export the GEXF file\n",
    "# This has additional benefits, such as being able to calculate specific node attributes and statistics\n",
    "\n",
    "# Export to CSV for Gephi\n",
    "gephi_nodes_df.to_csv(\"./gephi_nodes.csv\", index=False)\n",
    "gephi_edges_df.to_csv(\"./gephi_edges.csv\", index=False)\n",
    "\n",
    "\n",
    "# Then import and draw the Gephi graph as detailed below, before exporting the graph in GEXF format\n",
    "# Open and replace the GEXF declaration on line 2 of the GEXF file as follows:\n",
    "# <gexf version=\"1.2\" xmlns=\"http://www.gexf.net/1.2draft\" xmlns:viz=\"http://www.gexf.net/1.2/viz\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.gexf.net/1.2draft http://www.gexf.net/1.2draft/gexf.xsd\">\n",
    "\n",
    "# Import the Gephi GEXF export\n",
    "# graph = nx.read_gexf(\"./VECTR.gexf\")\n",
    "\n",
    "\n",
    "# Then call Sigma as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gephi Analysis\n",
    "\n",
    "\n",
    "### Data Laboratory: Data Import\n",
    "1. Create a New Project\n",
    "2. Switch to the Data Laboratory tab\n",
    "3. Select \"Import Spreadsheet\"\n",
    "4. Select `gephi_nodes.csv`, then click \"Next\" and \"Finish\"\n",
    "5. Set the \"Graph Type\" to \"Directed\"\n",
    "6. Set the \"Edges merge strategy\" to \"Don't merge\", then select \"Append to existing workspace\", then \"OK\"\n",
    "7. Select \"Import Spreadsheet\" again\n",
    "8. Select `gephi_edges.csv`, then click \"Next\" and \"Finish\"\n",
    "9. Set the \"Graph Type\" to \"Directed\"\n",
    "10. Set the \"Edges merge strategy\" to \"Don't merge\", then select \"Append to existing workspace\", then \"OK\"\n",
    "\n",
    "\n",
    "### Overview: Statistics: Calculate\n",
    "With the data imported, we can now draw the nodes and edges to our graph. We can use Gephi's powerful statistical capabilities to calculate various attributes for each data point, such as its degree and modularity, and use these to organise and resize each node accordingly.\n",
    "\n",
    "1. In the Statistics tab, run the \"Average Degree\" and \"Modularity\" plugins\n",
    "2. Under the Appearance tab, select Nodes ▶ Size ▶ Ranking ▶ Degree (Minimum 5, Maximum 30), then \"Apply\"\n",
    "3. Under the Appearance tab, select Nodes ▶ Colour ▶ Partition ▶ Modularity Class (Minimum 5, Maximum 30), then \"Apply\"\n",
    "\n",
    "\n",
    "### Overview: Layout: Drawing the Graph\n",
    "1. Select and run the Fruchterman Reingold model. This model attracts and repulses nodes based on their attributes\n",
    "2. Under Layout, select \"ForceAtlas 2\" ▶ Prevent Overlap\n",
    "3. Optionally, run the Expansion and/or the Noverlap models as necessary\n",
    "\n",
    "\n",
    "### Overview: Graph: Labels\n",
    "1. Below the main graph canvas, select the \"More settings ...\" icon\n",
    "2. Enable the Nodes checkbox, and set a suitable font\n",
    "3. Select the \"Configure ...\" button, and enable the \"Id\" checkbox, and disable the \"Label\" checkbox\n",
    "\n",
    "\n",
    "### Overview: Filters (Optional)\n",
    "A large VECTR dataset can result in hundreds of nodes being added to the graph. Thankfully, Gephi's filtering functionality can be used to remove statistically insignicant nodes from the graph.\n",
    "\n",
    "1. Ensure you have already calculated the appropriate node characteristics, detailed above\n",
    "2. In the Filters panel, select Library ▶ Attributes ▶ Range ▶ And select the appropriate node characteristic\n",
    "3. In the Queries panel below, expand Range ▶ Parameters, and set a sensible minimum value. The range of values can be explored using the Data Laboratory\n",
    "4. Click Filter\n",
    "\n",
    "\n",
    "### Preview: Customising and Exporting the Graph\n",
    "1. Select the Preview tab to view and export the graph\n",
    "2. Optionally, select a new Font\n",
    "3. Click the \"Refresh\" button after every adjustment to redraw the Graph\n",
    "\n",
    "\n",
    "### Export to GEXF\n",
    "1. File ▶ Export ▶ Graph File, then select `GEXF Files (*.gexf)` in the dropdown\n",
    "2. The `.gexf` file can be used as an input for ipysigma above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
